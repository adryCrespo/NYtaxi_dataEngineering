{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3ac694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bb3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SmallTestDataset\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d9c3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://24f1e701133a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SmallTestDataset</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x76740c604370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b99180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT DATA\n",
    "input_data_g = \"/home/jupyter/proyect/ds_taxi_NY/green_tripdata_2024-01.parquet\"\n",
    "input_data_y = \"/home/jupyter/proyect/ds_taxi_NY/yellow_tripdata_2024-01.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b312104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIltro registros\n",
    "registros_mes = \"01\"\n",
    "registros_year = \"2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838b89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES\n",
    "def sumar_missing_per_var(x):\n",
    "    \"\"\"conteo de missing en todas las variables del dataset\"\"\"\n",
    "    \n",
    "    return x.select([F.count( F.when(F.col(c).isNull(),c)  ).alias(c) for c in x.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed58d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[date_init_trip#601, PULocationID#534, DOLocationID#535], functions=[sum(total_amount#659), avg(total_amount#659), sum(passenger_count#536L)])\n",
      "+- Exchange hashpartitioning(date_init_trip#601, PULocationID#534, DOLocationID#535, 200), ENSURE_REQUIREMENTS, [id=#182]\n",
      "   +- *(1) HashAggregate(keys=[date_init_trip#601, PULocationID#534, DOLocationID#535], functions=[partial_sum(total_amount#659), partial_avg(total_amount#659), partial_sum(passenger_count#536L)])\n",
      "      +- *(1) Project [PULocationID#534, DOLocationID#535, passenger_count#536L, round((total_amount#545 + tip_amount#541), 2) AS total_amount#659, date_format(lpep_pickup_datetime#530, yyyy-MM-dd, Some(Etc/UTC)) AS date_init_trip#601]\n",
      "         +- *(1) ColumnarToRow\n",
      "            +- FileScan parquet [lpep_pickup_datetime#530,PULocationID#534,DOLocationID#535,passenger_count#536L,tip_amount#541,total_amount#545] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/jupyter/proyect/ds_taxi_NY/green_tripdata_2024-01.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<lpep_pickup_datetime:timestamp,PULocationID:int,DOLocationID:int,passenger_count:bigint,ti...\n",
      "\n",
      "\n",
      "+--------------+------------+------------+------------------+------------------+--------------------+\n",
      "|date_init_trip|PULocationID|DOLocationID| sum(total_amount)| avg(total_amount)|sum(passenger_count)|\n",
      "+--------------+------------+------------+------------------+------------------+--------------------+\n",
      "|    2024-01-01|          95|         192|              19.2|              19.2|                   1|\n",
      "|    2024-01-01|         152|          42|               8.7|               8.7|                   1|\n",
      "|    2024-01-02|          41|         230|61.099999999999994|30.549999999999997|                   7|\n",
      "|    2024-01-02|         166|         129|             65.02|             65.02|                   1|\n",
      "|    2024-01-02|          24|          74|              41.6|              20.8|                   7|\n",
      "|    2024-01-02|         129|         264|              20.0|              20.0|                   1|\n",
      "|    2024-01-03|         195|         228|              14.3|              14.3|                   2|\n",
      "|    2024-01-04|           7|          82|             46.48|             46.48|                   1|\n",
      "|    2024-01-04|          65|          33|             64.56|             16.14|                   5|\n",
      "|    2024-01-04|          43|         100|             28.65|             28.65|                   2|\n",
      "|    2024-01-04|         247|         186|              40.0|              40.0|                   1|\n",
      "|    2024-01-05|          75|          41|            204.44|15.726153846153846|                  13|\n",
      "|    2024-01-05|          97|         181|            192.18|            19.218|                  10|\n",
      "|    2024-01-06|          75|         100|             31.71|             31.71|                   1|\n",
      "|    2024-01-06|          41|          74|            115.68|11.568000000000001|                  10|\n",
      "|    2024-01-07|         181|         107|             29.45|             29.45|                   1|\n",
      "|    2024-01-07|          97|          62|              16.4|              16.4|                   1|\n",
      "|    2024-01-07|         130|         130|              76.0|              38.0|                   3|\n",
      "|    2024-01-07|          74|         179|             38.54|             38.54|                   2|\n",
      "|    2024-01-07|          82|         258|             62.34|             31.17|                   2|\n",
      "+--------------+------------+------------+------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#READ FILE GREEN\n",
    "df_g = spark.read.parquet(input_data_g)\n",
    "\n",
    "#SELECCION VARIABLES GREEN DATASET\n",
    "lista_vars = ['VendorID',\n",
    " 'lpep_pickup_datetime',\n",
    " 'lpep_dropoff_datetime',\n",
    " 'PULocationID',\n",
    " 'DOLocationID',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'tip_amount',\n",
    " 'total_amount']\n",
    "\n",
    "dfg = df_g.select(lista_vars)\n",
    "\n",
    "\n",
    "# FEATURE duracion_s: duracion del viaje en segundos\n",
    "dfg = dfg.withColumn('duracion_s', F.unix_timestamp(\"lpep_dropoff_datetime\") - F.unix_timestamp('lpep_pickup_datetime') )\\\n",
    "         .withColumn('duracion_s', F.when(  F.col('duracion_s')<0 , F.col('duracion_s')*-1 ).otherwise(F.col('duracion_s')) )\n",
    "\n",
    "# TRANSFORMACION REDONDEO TIEMPO, Y DATE GREEN TAXI\n",
    "dfg = dfg.withColumn(\"date_init_trip\", F.date_format(F.col(\"lpep_pickup_datetime\"), \"yyyy-MM-dd\"))\\\n",
    "         .withColumn( 'hour_init_trip',     F.hour( F.col(\"lpep_pickup_datetime\") ))\\\n",
    "         .drop(F.col('lpep_pickup_datetime'))\\\n",
    "         .drop( F.col('lpep_dropoff_datetime') )\n",
    "         \n",
    "\n",
    "# FEATURE tipoVehiculo: tipo vehiculo\n",
    "dfg = dfg.withColumn('tipoVehiculo', F.lit('Green'))\n",
    "\n",
    "dfg = dfg.withColumn('total_amount', F.round(F.col('total_amount')+F.col('tip_amount'),2)  )\n",
    "\n",
    "dfg = dfg.repartition(\"date_init_trip\")\n",
    "dfg1 = dfg.groupBy(\"date_init_trip\", \"PULocationID\",\"DOLocationID\").agg(F.sum('total_amount'), F.mean('total_amount'),F.sum(\"passenger_count\") )\n",
    "print(dfg1.rdd.getNumPartitions())\n",
    "dfg1.explain()\n",
    "\n",
    "dfg1.show(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05a207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.adaptive.enabled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
